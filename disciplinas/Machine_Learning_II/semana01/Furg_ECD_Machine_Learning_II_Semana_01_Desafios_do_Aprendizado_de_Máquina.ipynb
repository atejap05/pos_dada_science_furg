{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Furg - ECD - Machine Learning II - Semana 01 - Desafios do Aprendizado de Máquina",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atejap05/pos_data_science_furg/blob/main/disciplinas/Machine_Learning_II/semana01/Furg_ECD_Machine_Learning_II_Semana_01_Desafios_do_Aprendizado_de_M%C3%A1quina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32f2f004"
      },
      "source": [
        "# Curso de Especialização em Ciência de Dados - FURG\n",
        "## Machine Learning II - Desafios do Aprendizado de Máquina\n",
        "### Prof. Marcelo Malheiros\n",
        "\n",
        "---"
      ],
      "id": "32f2f004"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1db0f32a"
      },
      "source": [
        "# Inicialização\n",
        "\n",
        "Aqui importamos as bibliotecas fundamentais de Python para este _notebook_:\n",
        "\n",
        "- NumPy: suporte a vetores, matrizes e operações de Álgebra Linear\n",
        "- Matplotlib: biblioteca de visualização de dados\n",
        "- Pandas: pacote estatístico e de manipulação de DataFrames"
      ],
      "id": "1db0f32a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "527bbd1f"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "id": "527bbd1f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4d66bc1"
      },
      "source": [
        "# Lei dos grandes números\n",
        "\n",
        "Aqui fazemos uma demonstração simples dessa lei da Estatística, que mostra que para atingirmos o comportamento previsto precisamos de um grande número de amostras.\n",
        "\n",
        "Independentemente da distribuição probabilística do problema, com um número pequenos de amostras o ruído natural será muito maior que a tendência. Se isso não for considerado, pode gerar um viés de amostragem nos dados.\n",
        "\n",
        "O exemplo é feito através de um experimento simples de lançamentos de uma moeda, perfeitamente equilibrada. Ou seja, tanto **cara** como **coroa** terão exatamente 50% de chances em cada lançamento. Faremos 5 séries independentes, cada uma com inicialmente 20 lançamentos de moedas."
      ],
      "id": "b4d66bc1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3b3bd6c"
      },
      "source": [
        "prob_coroa = 0.5\n",
        "séries = 5\n",
        "lançamentos = 20"
      ],
      "id": "e3b3bd6c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9db5926"
      },
      "source": [
        "Uma representação fácil de visualizar é em uma matriz em que cada coluna é uma série de lançamentos, e em que cada linha é o n-ésimo lançamento de uma série. Usando um gerador de números com distribuição uniforme no intervalo $[0, 1)$, se for abaixo de 0.5 é **cara** (e portanto **0** na matriz) e caso contrário é **coroa** (ou **1** na matriz)."
      ],
      "id": "e9db5926"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45ce8272"
      },
      "source": [
        "# para garantir reprodutibilidade nas sequências aleatórias\n",
        "np.random.seed(42)\n",
        "\n",
        "# matriz com todos os lançamentos\n",
        "moedas = (np.random.uniform(size=(lançamentos, séries)) >= prob_coroa).astype(int)\n",
        "\n",
        "# probabilidade acumulativa de coroas em cada série\n",
        "percentual_coroas = np.cumsum(moedas, axis=0) / np.arange(1, lançamentos + 1).reshape(-1, 1)"
      ],
      "id": "45ce8272",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "422edf13"
      },
      "source": [
        "# função para plotagem de cada série com uma curva diferente\n",
        "def mostra_percentuais(percentuais, mínimo, máximo):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(percentuais)\n",
        "    plt.plot([0, percentuais.shape[0] - 1], [0.5, 0.5], 'k--', label='50%')\n",
        "    plt.xlabel('Número de lançamentos')\n",
        "    plt.ylabel('Percentual de coroas')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.axis([0, percentuais.shape[0] - 1, mínimo, máximo])\n",
        "    plt.show()"
      ],
      "id": "422edf13",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b7e766f"
      },
      "source": [
        "As curvas abaixo mostram o percentual **acumulativo** de coroas. Ou seja, qual a razão de coroas sobre as caras até cada momento.\n",
        "\n",
        "Como pode-se observar, há muita variação relativa entre caras e coroas nos lançamentos iniciais, o que explica a oscilação pronunciada das curvas."
      ],
      "id": "3b7e766f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b63ef4ed"
      },
      "source": [
        "mostra_percentuais(percentual_coroas, 0.0, 1.0)"
      ],
      "id": "b63ef4ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c59a6a5"
      },
      "source": [
        "Se aumentamos o número de lançamentos para 200, na escala do gráfico de 0 a 100% há uma convergência aparente de somente algumas séries para o valor esperado de 0.5."
      ],
      "id": "4c59a6a5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97e12854"
      },
      "source": [
        "lançamentos = 200\n",
        "\n",
        "np.random.seed(42)\n",
        "moedas = (np.random.uniform(size=(lançamentos, séries)) >= prob_coroa).astype(int)\n",
        "percentual_coroas = np.cumsum(moedas, axis=0) / np.arange(1, lançamentos + 1).reshape(-1, 1)\n",
        "mostra_percentuais(percentual_coroas, 0.0, 1.0)"
      ],
      "id": "97e12854",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4fa39fb"
      },
      "source": [
        "Para realmente termos uma convergência bem mais próxima para o valor esperado, precisamos aumentar o número de lançamentos para 20,000. E aproveitamos para dar um _zoom_, exibindo o comportamento das curvas muito mais próximo do valor esperado."
      ],
      "id": "f4fa39fb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29e26e7a"
      },
      "source": [
        "lançamentos = 20000\n",
        "\n",
        "np.random.seed(42)\n",
        "moedas = (np.random.uniform(size=(lançamentos, séries)) >= prob_coroa).astype(int)\n",
        "percentual_coroas = np.cumsum(moedas, axis=0) / np.arange(1, lançamentos + 1).reshape(-1, 1)\n",
        "mostra_percentuais(percentual_coroas, 0.42, 0.58)"
      ],
      "id": "29e26e7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "111503dd"
      },
      "source": [
        "# Geração de dados sintéticos\n",
        "\n",
        "Muitas vezes é importante testarmos algoritmos e visualizações usando dados aleatórios, porém criados de forma controlada.\n",
        "\n",
        "A seguir algumas \"receitas de bolo\" são dadas para criar uma nova coluna com dados sintéticos em um `DataFrame` do Pandas."
      ],
      "id": "111503dd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ee90cc2"
      },
      "source": [
        "# DataFrame vazio\n",
        "df = pd.DataFrame()"
      ],
      "id": "1ee90cc2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "674944d0"
      },
      "source": [
        "# 10 valores escolhidos aleatoriamente de uma lista (de strings ou de números)\n",
        "df['A'] = np.random.choice(size=10, a=['a', 'b', 'c'])"
      ],
      "id": "674944d0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "094289f8"
      },
      "source": [
        "# 10 valores escolhidos aleatoriamente de uma lista (de strings ou de números), com probabilidades específicas\n",
        "df['B'] = np.random.choice(size=10, a=['x', 'y', 'z'], p=[0.1, 0.3, 0.6])"
      ],
      "id": "094289f8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc74c446"
      },
      "source": [
        "# 10 valores inteiros uniformemente distribuídos entre 20 (dentro) e 50 (fora)\n",
        "df['C'] = np.random.randint(size=10, low=20, high=50)"
      ],
      "id": "bc74c446",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bab0717a"
      },
      "source": [
        "# 10 valores reais uniformemente distribuídos no intervalo [20.0, 50.0)\n",
        "df['D'] = np.random.uniform(size=10, low=20.0, high=50.0)"
      ],
      "id": "bab0717a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d941121"
      },
      "source": [
        "# 10 valores reais com distribuição normal de média 30.0 e desvio padrão 4.0\n",
        "df['E'] = np.random.normal(size=10, loc=30.0, scale=4.0)"
      ],
      "id": "6d941121",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd0a94b8"
      },
      "source": [
        "df"
      ],
      "id": "fd0a94b8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "103f0b76"
      },
      "source": [
        "Para usar outras distribuições estatísticas: https://numpy.org/doc/stable/reference/random/legacy.html#seeding-and-state"
      ],
      "id": "103f0b76"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcf185f1"
      },
      "source": [
        "# Cuidados com distribuições estatísticas\n",
        "\n",
        "Falando de distribuições estatísticas, ainda que as mais comuns sejam a **distribuição uniforme** e a **distribuição normal** (ou gaussiana), seu comportamento pode ser diferente da nossa intuição.\n",
        "\n",
        "Em particular, em uma distribuição uniforme os valores possíveis têm todos a mesma probabilidade de ocorrer (como no caso anterior dos lançamentos de uma moeda). Mas isso não quer dizer que a saída será homogênea, como poderia-se inicialmente supor.\n",
        "\n",
        "Para exemplificar, vamos gerar duas séries X e Y de 100 valores reais com distribuição uniforme entre 0 e 100:"
      ],
      "id": "fcf185f1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9b01524"
      },
      "source": [
        "np.random.seed(42)\n",
        "X = np.random.uniform(size=100, low=0.0, high=100.0)\n",
        "Y = np.random.uniform(size=100, low=0.0, high=100.0)"
      ],
      "id": "a9b01524",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15192e59"
      },
      "source": [
        "Se plotadas usando histogramas agrupando as dezenas, é possível ver a irregularidade na quantidade dos valores em cada faixa. Isso faz sentido levando-se em conta a **Lei dos grandes números**: a percepção de homogeneidade só vai acontecer gradativamente, quando mais pontos forem gerados para ambas as séries."
      ],
      "id": "15192e59"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f47d6459"
      },
      "source": [
        "plt.figure(figsize=(12, 2))\n",
        "plt.hist(X, color='tab:blue')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 2))\n",
        "plt.hist(Y, color='tab:orange')\n",
        "plt.show()"
      ],
      "id": "f47d6459",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1934a836"
      },
      "source": [
        "Já para 10,000 valores, temos os seguintes histogramas:"
      ],
      "id": "1934a836"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14d3a9d4"
      },
      "source": [
        "X = np.random.uniform(size=10000, low=0.0, high=100.0)\n",
        "Y = np.random.uniform(size=10000, low=0.0, high=100.0)\n",
        "\n",
        "plt.figure(figsize=(12, 2))\n",
        "plt.hist(X, color='tab:blue')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 2))\n",
        "plt.hist(Y, color='tab:orange')\n",
        "plt.show()"
      ],
      "id": "14d3a9d4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60fffffc"
      },
      "source": [
        "Essa percepção de dispersão se acentua quando interpretamos cada série como um dois atributos de uma mesma instância. Então, plotando um gráfico de dispersão em que X é a coordenada horizontal e Y a vertical, podemos ver que mesmo 10,000 pontos cobrem de maneira irregular o quadrado de todas as possibilidades. Essa é a **maldição da dimensionalidade**."
      ],
      "id": "60fffffc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b761f205"
      },
      "source": [
        "plt.figure(figsize=(5, 5))\n",
        "plt.plot(X, Y, 'r.', alpha=0.5)\n",
        "plt.show()"
      ],
      "id": "b761f205",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "242d61b4"
      },
      "source": [
        "Se a aplicação demanda gerar amostras bem distribuídas em um intervalo, justamente para reduzir erros de amostragem, não é adequado usar valores aleatórios. O ideal nesta situação é usar procedimentos mais elaborados, como por exemplo [sequências de baixa discrepância](https://en.wikipedia.org/wiki/Low-discrepancy_sequence), como a [sequência de Sobol](https://en.wikipedia.org/wiki/Sobol_sequence)."
      ],
      "id": "242d61b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae72f9f6"
      },
      "source": [
        "# Limitações de medidas descritivas e de correlação\n",
        "\n",
        "Um exemplo clássico para ilustrar as limitações de medidas estatísticas descritivas é o [Quarteto de Anscombe](https://en.wikipedia.org/wiki/Anscombe%27s_quartet).\n",
        "\n",
        "Basicamente são quatro curtas séries de dados visualmente bem distintas, mas que têm as principais medidas descritivas praticamente idênticas ([código original](https://matplotlib.org/stable/gallery/specialty_plots/anscombe.html))."
      ],
      "id": "ae72f9f6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28543c25"
      },
      "source": [
        "x = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]\n",
        "y1 = [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68]\n",
        "y2 = [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74]\n",
        "y3 = [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73]\n",
        "x4 = [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8]\n",
        "y4 = [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]\n",
        "\n",
        "datasets = {'I': (x, y1), 'II': (x, y2), 'III': (x, y3), 'IV': (x4, y4)}\n",
        "fig, axs = plt.subplots(1, 4, sharex=True, sharey=True, figsize=(16, 4), tight_layout=True)\n",
        "axs[0].set(xlim=(0, 20), ylim=(2, 14))\n",
        "axs[0].set(xticks=(0, 10, 20), yticks=(4, 8, 12))\n",
        "\n",
        "for ax, (label, (x, y)) in zip(axs.flat, datasets.items()):\n",
        "    ax.text(0.1, 0.9, label, fontsize=20, transform=ax.transAxes, va='top')\n",
        "    ax.tick_params(direction='in', top=True, right=True)\n",
        "    ax.plot(x, y, 'o')\n",
        "\n",
        "    # linha vermelha: regressão linear\n",
        "    p1, p0 = np.polyfit(x, y, deg=1) # inclinação, ponto de interseção\n",
        "    ax.plot([0, 20], [p0, 20 * p1 + p0])\n",
        "\n",
        "    # legenda\n",
        "    stats = (f'média = {np.mean(y):.2f}\\n'\n",
        "             f'desv. padrão = {np.std(y):.2f}\\n'\n",
        "             f'coef. R = {np.corrcoef(x, y)[0][1]:.2f}')\n",
        "    bbox = dict(boxstyle='round', fc='blanchedalmond', ec='orange', alpha=0.5)\n",
        "    ax.text(0.95, 0.07, stats, fontsize=12, bbox=bbox, transform=ax.transAxes, horizontalalignment='right')\n",
        "\n",
        "plt.show()"
      ],
      "id": "28543c25",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0030ace4"
      },
      "source": [
        "Na verdade, com um pouco de Álgebra Linear é possível construir dados sintéticos bastante distintos e ainda com medidas descritivas muito similares.\n",
        "\n",
        "No exemplo abaixo vamos criar sinteticamente duas séries de dados X e Y, usando valores aleatórios como antes. Porém, vamos **reprojetar** os valores de Y em uma série semelhante Z, de forma a garantir que as séries X e Z tenham um coeficiente de correlação R especificado previamente."
      ],
      "id": "0030ace4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64aa95d1"
      },
      "source": [
        "# Função para criar uma nova série de valores baseada em y, agora ajustada para\n",
        "# ter o coeficiente de correlação r em relação a x.\n",
        "# Traduzida de R para Python, a partir de https://github.com/janhove/cannonball\n",
        "\n",
        "def reprojetar_y(x, y, r):\n",
        "    theta = np.arccos(r)\n",
        "    Xctr  = np.column_stack((x - x.mean(), y - y.mean()))\n",
        "    Id    = np.eye(x.shape[0])\n",
        "    Q, _  = np.linalg.qr(Xctr[:, [0]])\n",
        "    P     = Q * Q.T\n",
        "    x2o   = np.dot(Id - P, Xctr[:, 1])\n",
        "    Xc2   = np.column_stack((Xctr[:, 0], x2o))\n",
        "    Y     = np.dot(Xc2, np.diag(1 / np.sqrt(np.sum(Xc2 * Xc2, axis=0))))\n",
        "    y     = Y[:, 1] + (1 / np.tan(theta)) * Y[:, 0]\n",
        "    return y"
      ],
      "id": "64aa95d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2945f689"
      },
      "source": [
        "# função auxiliar, para normalizar uma série de valores para o intervalo [0, 1]\n",
        "\n",
        "def normalizar(a):\n",
        "    return (a - min(a)) / (max(a) - min(a))"
      ],
      "id": "2945f689",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bbc0018"
      },
      "source": [
        "Para o primeiro exemplo geramos duas séries X e Y com 100 valores aleatórios distribuídos de forma normal, ou seja, segundo uma distribuição gaussiana.\n",
        "\n",
        "A nova série Z é construída para ter correlação 0.328 com X. Qualquer outro valor de R no intervalo $[-1, 1)$ também pode ser alcançado."
      ],
      "id": "8bbc0018"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afd09d2e"
      },
      "source": [
        "np.random.seed(42)\n",
        "X = normalizar(np.random.normal(size=100))\n",
        "Y = normalizar(np.random.normal(size=100))\n",
        "Z = normalizar(reprojetar_y(X, Y, r=0.82))\n",
        "print(f'R antes: {np.corrcoef(X, Y)[0, 1]:+.3}', f'R depois: {np.corrcoef(X, Z)[0, 1]:+.3}')\n",
        "plt.figure(figsize=(5, 5))\n",
        "#plt.plot(X, Y, 'c.')\n",
        "plt.plot(X, Z, 'ob')\n",
        "plt.show()"
      ],
      "id": "afd09d2e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cf86488"
      },
      "source": [
        "A seguir criamos os valores de X perfeitamente espaçados, e geramos os valores de Y segundo uma função senóide.\n",
        "\n",
        "Novamente é possível gerar uma série Z visualmente bastante similar, ainda que com o mesmo coeficiente de correlação 0.328."
      ],
      "id": "3cf86488"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc08bd4b"
      },
      "source": [
        "np.random.seed(42)\n",
        "X = normalizar(np.arange(0, 100))\n",
        "Y = normalizar(np.sin(X * 10))\n",
        "Z = normalizar(reprojetar_y(X, Y, r=0.528))\n",
        "print(f'R antes: {np.corrcoef(X, Y)[0, 1]:+.3}', f'R depois: {np.corrcoef(X, Z)[0, 1]:+.3}')\n",
        "plt.figure(figsize=(5, 5))\n",
        "#plt.plot(X, Y, 'c.')\n",
        "plt.plot(X, Z, 'ob')\n",
        "plt.show()"
      ],
      "id": "dc08bd4b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a004e285"
      },
      "source": [
        "# Ferramentas para análise visual da dispersão\n",
        "\n",
        "Naturalmente que a correlação é uma medida importante, e não deve ser descartada. Porém, deve ser entendida no contexto de uma **possível relação linear entre dois atributos**.\n",
        "\n",
        "O ideal é sempre acompanhar a análise descritiva de uma visualização usando também **histogramas** e **gráficos de dispersão**.\n",
        "\n",
        "A seguir eu recomendo três ferramentas de apoio nesse sentido. Para ilustrar, vamos utilizar novamente o clássico _dataset_ IRIS, carregado abaixo para um `DataFrame`."
      ],
      "id": "a004e285"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de628291"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "dataset = load_iris()\n",
        "iris = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
        "iris['label'] = pd.Series([dataset.target_names[k] for k in dataset.target])"
      ],
      "id": "de628291",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6493a280"
      },
      "source": [
        "iris"
      ],
      "id": "6493a280",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c937ac6a"
      },
      "source": [
        "## Matriz de correlação do Pandas\n",
        "\n",
        "Uma ferramenta bastante simples e que já foi vista é a matriz de correlações entre atributos numéricos, obtida pela função `.corr()` de um `DataFrame`."
      ],
      "id": "c937ac6a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3ecc89e"
      },
      "source": [
        "corr = iris.corr()\n",
        "\n",
        "# quanto cada atributo se correlaciona com o valor de 'petal length (cm)'\n",
        "corr['petal length (cm)'].sort_values(ascending=False)"
      ],
      "id": "e3ecc89e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d28b9ab7"
      },
      "source": [
        "corr"
      ],
      "id": "d28b9ab7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffa20052"
      },
      "source": [
        "corr.style.background_gradient(axis=None, cmap='bwr')"
      ],
      "id": "ffa20052",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b810c77d"
      },
      "source": [
        "## Matriz de dispersão do Pandas\n",
        "\n",
        "A biblioteca Pandas possui um recurso bem mais sofisticado, que usa a mesma estrutura de matriz para plotar diversos diagramas de dispersão entre os atributos. Além disso, um histograma de cada atributo também é mostrado na diagonal da matriz.\n",
        "\n",
        "No exemplo abaixo adicionamos ainda uma informação visual de cor, colorindo os rótulos com cores distintas, o que permite examinar a distribuição espacial de cada categoria do _dataset_."
      ],
      "id": "b810c77d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "469c1695"
      },
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "colors = {'setosa': 'red', 'versicolor': 'green', 'virginica': 'blue'}\n",
        "scatter_matrix(iris, figsize=(12, 12), color=[colors[l] for l in iris.label], alpha=1.0)\n",
        "plt.show()"
      ],
      "id": "469c1695",
      "execution_count": null,
      "outputs": []
    }
  ]
}